# BAXperience Data Processor

Servicio encargado de procesar datos crudos de CSVs y transformarlos para el sistema de recomendaciones y clustering.

## Arquitectura de Datos

```
CSVs Filtrados ‚Üí BD Operacional ‚Üí BD Data Processor ‚Üí Clustering/ML
     ‚Üì              ‚Üì                    ‚Üì               ‚Üì
   Raw Data    Complete Data      Optimized Data    Recommendations
```

### Bases de Datos

1. **BD Operacional**: Base de datos completa con todos los usuarios, POIs, itinerarios y valoraciones
2. **BD Data Processor**: Base de datos optimizada para clustering y an√°lisis con datos normalizados

## Instalaci√≥n

### 1. Dependencias

```bash
cd baxperience-backend/services/data-processor-service
pip install -r requirements.txt
```

### 2. Configuraci√≥n de Base de Datos

Copia el archivo de configuraci√≥n:
```bash
cp env.example .env
```

Edita `.env` con tus credenciales de base de datos:
```env
# BD Operacional
OPERATIONAL_DB_HOST=localhost
OPERATIONAL_DB_PORT=5432
OPERATIONAL_DB_NAME=baxperience_operational
OPERATIONAL_DB_USER=postgres
OPERATIONAL_DB_PASSWORD=tu_password

# BD Data Processor
PROCESSOR_DB_HOST=localhost
PROCESSOR_DB_PORT=5433
PROCESSOR_DB_NAME=baxperience_processor
PROCESSOR_DB_USER=postgres
PROCESSOR_DB_PASSWORD=tu_password
```

### 3. Crear Bases de Datos

```sql
-- BD Operacional
CREATE DATABASE baxperience_operational;

-- BD Data Processor  
CREATE DATABASE baxperience_processor;
```

### 4. Crear Esquema Operacional

```bash
psql -h localhost -p 5432 -U postgres -d baxperience_operational -f baxperience_operational_db.sql
```

## Uso

### Pipeline Completo (Recomendado)

```bash
python main.py --mode=full
```

Este comando ejecuta:
1. ‚úÖ Procesamiento de CSVs ‚Üí BD Operacional
2. ‚úÖ ETL: BD Operacional ‚Üí BD Data Processor
3. üîÑ Clustering (pr√≥ximamente)

### Solo Procesamiento de CSVs

```bash
python main.py --mode=csv
```

### Solo ETL

```bash
python main.py --mode=etl
```

### Modo Verbose

```bash
python main.py --mode=full --verbose
```

## Estructura de Archivos

```
data-processor-service/
‚îú‚îÄ‚îÄ main.py                        # Orquestador principal
‚îú‚îÄ‚îÄ csv_processor.py               # Procesador de CSVs ‚Üí BD Operacional
‚îú‚îÄ‚îÄ etl_to_processor.py           # ETL: BD Operacional ‚Üí BD Data Processor
‚îú‚îÄ‚îÄ baxperience_operational_db.sql # Esquema BD Operacional
‚îú‚îÄ‚îÄ requirements.txt               # Dependencias Python
‚îú‚îÄ‚îÄ env.example                   # Configuraci√≥n de ejemplo
‚îî‚îÄ‚îÄ README_PROCESSOR.md           # Esta documentaci√≥n
```

## Procesamiento de CSVs

### CSVs Soportados

| CSV | Categor√≠a | Registros Aprox. | Campos Clave |
|-----|-----------|------------------|--------------|
| `museos-filtrado.csv` | Museos | ~130 | nombre, direccion, latitud, longitud |
| `oferta-gastronomica.csv` | Gastronom√≠a | ~2800 | nombre, categoria, cocina, barrio |
| `monumentos-caba.csv` | Monumentos | ~140 | denominacion, material, autor |
| `lugares-historicos-filtrado.csv` | Lugares Hist√≥ricos | ~400 | nombre, jurisdiccion |
| `salas-cine-filtrado.csv` | Entretenimiento | ~40 | nombre, pantallas, butacas |

### Funciones de Procesamiento

Cada CSV tiene su propia funci√≥n especializada:

- `process_museos_csv()`: Procesa museos con l√≥gica de subcategorizaci√≥n autom√°tica
- `process_gastronomia_csv()`: Mapea categor√≠as gastron√≥micas (restaurante, caf√©, bar, etc.)
- `process_monumentos_csv()`: Extrae informaci√≥n de material y autor
- `process_lugares_historicos_csv()`: Procesa sitios patrimoniales
- `process_cines_csv()`: Procesa salas de cine con capacidad

### Mapeo de Categor√≠as

```python
# Ejemplo de mapeo autom√°tico
if 'arte' in nombre.lower():
    subcategoria = 'Museos de Arte'
elif 'historia' in nombre.lower():
    subcategoria = 'Museos de Historia'
```

## ETL a Data Processor

### Transformaciones Aplicadas

1. **Normalizaci√≥n de Coordenadas**: Validaci√≥n y limpieza de lat/lng
2. **Score de Popularidad**: Calculado como `valoraci√≥n * log(reviews + 1)`
3. **Features Binarios**: `tiene_web`, `tiene_telefono`, `es_gratuito`
4. **M√©tricas por Barrio**: Agregaciones para clustering geogr√°fico
5. **Features Temporales**: Para eventos (mes, d√≠a de semana, duraci√≥n)

### Esquema Data Processor

```sql
lugares_clustering (
    poi_id, nombre, categoria,
    latitud, longitud, barrio,
    valoracion_promedio, popularidad_score,
    tipo_cocina, tipo_ambiente,
    tiene_web, tiene_telefono, es_gratuito
)

metricas_barrio (
    barrio, total_pois, total_museos,
    valoracion_promedio_barrio,
    centroide_lat, centroide_lng
)

eventos_clustering (
    evento_id, categoria_evento,
    fecha_inicio, mes_inicio, dia_semana_inicio,
    entrada_libre, capacidad_maxima
)
```

## Logs y Monitoreo

### Archivos de Log

- `csv_processor.log`: Logs del procesamiento de CSVs
- `etl_processor.log`: Logs del ETL
- `data_processor_main.log`: Logs del orquestador principal

### M√©tricas de Procesamiento

El sistema reporta:
- ‚úÖ Registros procesados exitosamente
- ‚ùå Errores y registros omitidos
- ‚è±Ô∏è Tiempo de ejecuci√≥n
- üìä Estad√≠sticas por categor√≠a

## Troubleshooting

### Error de Conexi√≥n a BD

```
‚ùå Error conectando a bases de datos: FATAL: database "baxperience_operational" does not exist
```

**Soluci√≥n**: Crear la base de datos:
```sql
CREATE DATABASE baxperience_operational;
```

### Error de Coordenadas

```
‚ö†Ô∏è Museo sin coordenadas: Nombre del Museo
```

**Causa**: El CSV tiene valores nulos en latitud/longitud
**Resultado**: El registro se omite (se requieren coordenadas para clustering)

### Error de Categor√≠a No Encontrada

```
‚ùå Error: Categor√≠a 'nueva_categoria' no existe
```

**Soluci√≥n**: Verificar que las categor√≠as est√©n insertadas en la BD:
```sql
SELECT * FROM categorias;
```

## Pr√≥ximos Pasos

### Clustering (En Desarrollo)

1. **K-Means Geogr√°fico**: Agrupar POIs por proximidad
2. **Clustering Tem√°tico**: Agrupar por categor√≠a y caracter√≠sticas
3. **Clustering Temporal**: Para eventos por fechas y estacionalidad
4. **Clustering H√≠brido**: Combinar ubicaci√≥n, tema y tiempo

### Integraci√≥n con Scraper

El sistema est√° preparado para recibir eventos del scraper service:
- Tabla `eventos` lista para nuevos registros
- ETL autom√°tico de eventos activos
- Limpieza autom√°tica de eventos vencidos

### API de Recomendaciones

Pr√≥ximamente se agregar√° una API que consuma los clusters para generar recomendaciones personalizadas basadas en:
- Ubicaci√≥n del usuario
- Preferencias de categor√≠as
- Fechas de viaje
- Patrones de clustering

## Contribuir

Para agregar nuevos CSVs:

1. Crear funci√≥n `process_nuevo_csv()` en `csv_processor.py`
2. Agregar mapeo de categor√≠as correspondiente
3. Actualizar `process_all_csvs()` para incluir la nueva funci√≥n
4. Probar con datos de ejemplo

Para modificar el ETL:

1. Actualizar transformaciones en `etl_to_processor.py`
2. Modificar esquema de `lugares_clustering` si es necesario
3. Regenerar datos con `python main.py --mode=etl`
